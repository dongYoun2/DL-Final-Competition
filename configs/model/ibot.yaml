# @package _global_
model:
  name: ibot
  architecture: vit_small_patch16_224 # actual image size will be overridden by data.image_size

  # Vision Transformer settings
  vit:
    img_size: 96  # Will be overridden by data.image_size
    # patch_size: 8  # 96/8 = 12 patches per side (144 total patches)
    patch_size: 16  # 96/16 = 6 patches per side (36 total patches)
    embed_dim: 384  # Smaller for 96x96 images
    depth: 12
    num_heads: 6
    mlp_ratio: 4.0
    drop_path_rate: 0.1

  # IBOT specific settings
  ibot:
    out_dim: 8192
    patch_out_dim: 8192
    norm_last_layer: false
    momentum_teacher: 0.996
    teacher_temp: 0.04
    warmup_teacher_temp: 0.04
    warmup_teacher_temp_epochs: 30
    student_temp: 0.1

    # Multi-crop settings
    global_crops_scale: [0.4, 1.0]
    local_crops_scale: [0.05, 0.4]
    # local_crops_number: 8
    # local_crops_number: 2
    local_crops_number: 0

    # MIM (Masked Image Modeling) settings
    pred_ratio: 0.0 # turn off
    pred_ratio_var: 0.0
    pred_shape: block
    pred_start_epoch: 0

    # Loss weights
    lambda1: 1.0  # CLS token loss weight
    lambda2: 1.0  # Patch token loss weight

  # Pretrained weights
  pretrained: null
