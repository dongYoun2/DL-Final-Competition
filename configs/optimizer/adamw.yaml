# @package _global_
optimizer:
  name: adamw
  lr: 0.0005
  weight_decay: 0.04        # starting value (early training)
  weight_decay_end: 0.4     # cosine target (late training)
  betas: [0.9, 0.999]
  eps: 1.0e-8




